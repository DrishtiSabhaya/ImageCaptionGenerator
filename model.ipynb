{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SEK9s0akFWbs9TfYZAGMfzQjkOXTsZGj",
      "authorship_tag": "ABX9TyPxnwKgGsg8q1xmR6rZbZeA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrishtiSabhaya/ImageCaptionGenerator/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5INZgQhDlc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def load_description(text):\n",
        "\tmapping = dict()\n",
        "\tfor line in text.split('\\n'):\n",
        "\t\ttoken = line.split()\n",
        "\t\tif len(line)<2:\n",
        "\t\t\tcontinue\n",
        "\t\timg_id, img_desc = token[0], token[1:]\n",
        "\t\timg_id = img_id.split('.')[0]\n",
        "\t\timg_desc = ' '.join(img_desc)\n",
        "\t\tif img_id not in mapping:                            \n",
        "\t\t\tmapping[img_id] = list()\n",
        "\t\tmapping[img_id].append(img_desc)\n",
        "\treturn mapping\n",
        "\n",
        "def clean_text(descriptions):\n",
        "\ttable = str.maketrans('', '', string.punctuation)      # translation table for removing all types of punctuation\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor i in range(len(desc_list)):\n",
        "\t\t\tdesc = desc_list[i]\n",
        "\t\t\tdesc = desc.split()\n",
        "\t\t\tdesc = [word.lower() for word in desc]\n",
        "\t\t\tdesc = [w.translate(table) for w in desc]\n",
        "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
        "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
        "\t\t\tdesc_list[i] = ' '.join(desc)\n",
        "\t\t\t\n",
        "def save_desc(descriptions, file2):\n",
        "\tlines = []\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\tlines.append(key+' '+desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tf = open(file2,'w')\n",
        "\tf.write(data)\n",
        "\tf.close()\n",
        "\t\n",
        "\n",
        "\t\n",
        "file1 = open('Flickr8k.token.txt','r')\n",
        "text = file1.read()\n",
        "\n",
        "descriptions = load_description(text)\n",
        "clean_text(descriptions)\n",
        "save_desc(descriptions,'desc.txt')\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_DbPNQlleEmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "6063a242-6b74-41fe-faa9-b35c046ae129"
      },
      "source": [
        "import pickle\n",
        "from os import listdir\n",
        "from pickle import dump\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "\n",
        "def extract_features(directory):\n",
        "\tmodel = VGG16()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "\tprint(model.summary())\n",
        "\t\n",
        "\tfeatures = dict()\n",
        "\tfor name in listdir(directory):\n",
        "\t\tfile1 = directory +'/'+ name\n",
        "\t\timage = load_img(file1, target_size=(224,224))\n",
        "\t\timage = img_to_array(image)\n",
        "\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t\timage = preprocess_input(image)\n",
        "\t\tfeature = model.predict(image, verbose=0)\n",
        "\t\timg_id = name.split('.')[0]\n",
        "\t\tfeatures[img_id] = feature\n",
        "\treturn features\n",
        "\n",
        "directory = '/content/drive/My Drive/Datasets/Images/Flicker8k_Dataset'\n",
        "features = extract_features(directory)\n",
        "print(len(features))\n",
        "\n",
        "pickle.dump(features,open('features.pkl','wb'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "8091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Hcin_GEnfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "outputId": "69fd109e-75a8-4c66-9ac8-15afdb4f21c2"
      },
      "source": [
        "from numpy import array\n",
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def load_set(filename):\n",
        "\tfile1 = open(filename,'r')\n",
        "\ttext = file1.read()\n",
        "\tfile1.close()\n",
        "\tdataset = []\n",
        "\tfor line in text.split('\\n'):\n",
        "\t\tif len(line)<1:\n",
        "\t\t\tcontinue\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\t\n",
        "def load_desc(filename,dataset):\n",
        "\tfile2 = open(filename,'r')\n",
        "\tdoc = file2.read()\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\timg_id, img_desc = tokens[0], tokens[1:]\n",
        "\t\tif img_id in dataset:\n",
        "\t\t\tif img_id not in descriptions:\n",
        "\t\t\t\tdescriptions[img_id] = list()\n",
        "\t\t\tdesc = 'start' + ' '.join(img_desc) + 'end'\n",
        "\t\t\tdescriptions[img_id].append(desc)\n",
        "\treturn descriptions\n",
        "\t\n",
        "def load_features(filename, dataset):\n",
        "\t# load all features\n",
        "\tl = []\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\t# filter features\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features\n",
        "\t\n",
        "def to_line(descriptions):\n",
        "\tdesc = []\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[desc.append(value) for value in descriptions[key]]\n",
        "\treturn desc\n",
        "\t\n",
        "def tokenize(descriptions):\n",
        "\tlines = to_line(descriptions)\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\t\n",
        "def max_length(descriptions):\t\n",
        "\tlines = to_line(descriptions)\n",
        "\treturn max(len(d.split())for d in lines)\n",
        "\t\n",
        "def sequences(tokenizer, max_length, desc_list, photos, vocab_size):\n",
        "\tX1, X2, y = [], [], []\n",
        "\tfor desc in desc_list:\n",
        "\t\tseq = tokenizer.texts_to_sequences([desc])[0]                          #encode the sequence\n",
        "\t\tfor i in range(1,len(seq)):\n",
        "\t\t\tin_seq, out_seq = seq[:i], seq[i]                                  # split into input and output pair\n",
        "\t\t\tin_seq = pad_sequences([in_seq], maxlen = max_length)[0]            #pad sequences to match length of every sequence\n",
        "\t\t\tout_seq = to_categorical([out_seq], num_classes = vocab_size)[0]\n",
        "\t\t\t\t\n",
        "\t\t\tX1.append(photos)\n",
        "\t\t\tX2.append(in_seq)\n",
        "\t\t\ty.append(out_seq)\n",
        "\t\t\t\t\n",
        "\treturn array(X1), array(X2), array(y)\n",
        "\t\n",
        "def def_model(vocab_size, max_length):\n",
        "\tinputs1 = Input(shape=(4096,))\n",
        "\tfe1 = Dropout(0.5)(inputs1)\n",
        "\tfe2 = Dense(256, activation = 'relu')(fe1)\n",
        "\t\n",
        "\tinputs2 = Input(shape=(max_length,))\n",
        "\tse1 = Embedding(vocab_size, 256, mask_zero = True)(inputs2)\n",
        "\tse2 = Dropout(0.5)(se1)\n",
        "\tse3 = LSTM(256)(se2)\n",
        "\t\n",
        "\tdecoder1 = add([fe2, se3])\n",
        "\tdecoder2 = Dense(256, activation = 'relu')(decoder1)\n",
        "\toutputs = Dense(vocab_size, activation = 'softmax')(decoder2)\n",
        "\t\n",
        "\tmodel = Model(inputs = [inputs1, inputs2], outputs = outputs)\n",
        "\tmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "\tmodel.summary()\n",
        "\tplot_model(model, to_file = 'model.png', show_shapes = True)\n",
        "\treturn model\n",
        "\t\n",
        "def data_generator(descriptions, photos, tokenizer, max_length, vocab_size):\n",
        "\twhile 1:\n",
        "\t\tfor key, desc_list in descriptions.items():\n",
        "\t\t\tphoto = photos[key][0]\n",
        "\t\t\tin_img, in_seq, out_word = sequences(tokenizer, max_length, desc_list, photo, vocab_size)\n",
        "\t\t\tyield [in_img, in_seq], out_word\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\n",
        "filename = 'Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "train_desc = load_desc('desc.txt',train)\n",
        "train_features = load_features('features.pkl',train)\n",
        "\n",
        "tokenizer = tokenize(train_desc)\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "max_length = max_length(train_desc)\n",
        "\n",
        "model = def_model(vocab_size, max_length)\n",
        "epochs = 20\n",
        "steps = len(train_desc)\n",
        "for i in range(epochs):\n",
        "\tgenerator = data_generator(train_desc, train_features, tokenizer, max_length, vocab_size)\n",
        "\tmodel.fit_generator(generator, epochs = 1, steps_per_epoch = steps, verbose = 2)\n",
        "\tmodel.save('model_'+str(i)+'.h5')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 4096)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 32, 256)      2662400     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 4096)         0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 256)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          1048832     dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 256)          525312      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256)          0           dense[0][0]                      \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10400)        2672800     dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,975,136\n",
            "Trainable params: 6,975,136\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From <ipython-input-3-a4a86ab7269f>:123: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "6000/6000 - 597s - loss: 5.4575\n",
            "6000/6000 - 606s - loss: 4.4554\n",
            "6000/6000 - 605s - loss: 4.1344\n",
            "6000/6000 - 605s - loss: 3.9345\n",
            "6000/6000 - 601s - loss: 3.8289\n",
            "6000/6000 - 601s - loss: 3.7210\n",
            "6000/6000 - 593s - loss: 3.6226\n",
            "6000/6000 - 600s - loss: 3.5664\n",
            "6000/6000 - 602s - loss: 3.5183\n",
            "6000/6000 - 593s - loss: 3.4684\n",
            "6000/6000 - 592s - loss: 3.4314\n",
            "6000/6000 - 592s - loss: 3.4050\n",
            "6000/6000 - 597s - loss: 3.3750\n",
            "6000/6000 - 595s - loss: 3.3518\n",
            "6000/6000 - 596s - loss: 3.3427\n",
            "6000/6000 - 600s - loss: 3.3086\n",
            "6000/6000 - 596s - loss: 3.2950\n",
            "6000/6000 - 583s - loss: 3.2750\n",
            "6000/6000 - 576s - loss: 3.2648\n",
            "6000/6000 - 579s - loss: 3.2602\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}